{
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "name": "",
  "signature": "sha256:f072b4b82b12aabd8dca030eca8756da78f8c8ec5c369eafe179fbfc12550e81"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Using AMRICA\n",
      "\n",
      "AMRICA (AMR Inspector for Cross-language Alignments) is a simple tool for aligning and visually representing AMRs [(Banarescu, 2013)](http://www.isi.edu/natural-language/amr/a.pdf), both for bilingual contexts and for monolingual inter-annotator agreement. It is based on and extends the Smatch system [(Cai, 2012)](http://www.newdesign.aclweb.org/anthology-new/P/P13/P13-2131.pdf) for identifying AMR interannotator agreement.\n",
      "\n",
      "## How It Works\n",
      "\n",
      "### Smatch Classic\n",
      "\n",
      "Since AMRICA is a variation on Smatch, one should begin by understanding Smatch. Smatch attempts to identfy a matching between the variable nodes of two AMR representations of the same sentence in order to measure inter-annotator agreement. The matching should be selected to maximize the Smatch score, which assigns a point for each edge appearing in both graphs, falling into three categories. Each category is illustrated in the following annotation of \"It didn't take long.\"\n",
      "\n",
      "```\n",
      "(t / take-10\n",
      "  :ARG0 (i / it)\n",
      "  :ARG1 (l2 / long\n",
      "          :polarity -))\n",
      "```\n",
      "\n",
      "* Instance labels, such as `(instance, t, take-10)`\n",
      "* Variable-variable edges, such as `(ARG0, t, i)`\n",
      "* Variable-const edges, such as `(polarity, l2, -)`\n",
      "\n",
      "Because the problem of finding the matching maximizing the Smatch score is NP-complete, Smatch uses a hill-climbing algorithm to approximate the best solution. It seeds by matching each node to a node sharing its label if possible and matching the remaining nodes in the smaller graph (hereafter the target) randomly. Smatch then performs a step by finding the action that will increase the score the most by either switching two target nodes' matchings or moving a matching from its source node to an unmatched source node. It repeats this step until no step can immediately increase the Smatch score.\n",
      "\n",
      "To avoid local optima, Smatch generally restarts 5 times.\n",
      "\n",
      "### AMRICA\n",
      "\n",
      "AMRICA begins by replacing all constant nodes with variable nodes that are instances of the constant's label. This is necessary so we can align the constant nodes as well as the variables. So the only points added to AMRICA score will come from matching variable-variable edges and instance labels.\n",
      "\n",
      "While Smatch tries to match every node in the smaller graph to some node in the larger graph, AMRICA removes matchings that do not increase the modified Smatch score, or AMRICA score.\n",
      "\n",
      "AMRICA then generates image files from graphviz graphs of the alignments. If a node or edge appears only in the gold data, it is red. If that node or edge appears only in the test data, it is blue. If the node or edge has a matching in our final alignment, it is black.\n",
      "\n",
      "<img src=\"DF-183-195681-794_9333.5_annoted_UCO-AMR-06_UCO-AMR-05.png\">\n",
      "\n",
      "#### Bitextual Variant\n",
      "\n",
      "In AMRICA, instead of adding one point for each perfectly matching instance label, we add a point based on a likelihood score on those labels aligning. The likelihood score $\\ell(a_{L_t,L_s}[i] | L_t, W_t, L_s, W_s)$ with target label set $L_t$, source labels set $L_s$, target sentence $W_t$, source sentence $W_s$, and  alignment $a_{L_t,L_s}[i]$ mapping $L_{t}[i]$ onto some label $L_{s}[a_{L_t,L_s}[i]]$, is computed from a likelihood that is defined by the following rules:\n",
      "\n",
      "* If the labels for $L_s[a_{L_t,L_s}[i]]$ and $L_t[i]$ match, add 1 to the likelihood.\n",
      "* Add to the likelihood\n",
      "$$\\sum_{j = 1}^{|W_t|} \\sum_{k = 1}^{|W_s|} \\ell(a_{L_t,W_t}[i] = j) \\ell(a_{W_t,W_s}[j] = k) \\ell(a_{W_s,L_s}[k] = a_{L_t, L_s}[i])$$\n",
      "    * Compute $\\ell(a_{L_t,W_t}[i] = j)$ by one of two methods.\n",
      "        * If there are JAMR alignments available, for each JAMR alignment containing this node, 1 point is partitioned among the tokens in the range aligned to the label. If there are no such tokens in the range, the 1 point is partitioned among all tokens in the range.\n",
      "            * If no JAMR alignment contains the $i^{\\textit{th}}$ node, treat it as though the token ranges with no JAMR aligned nodes were aligned to the $i^{\\textit{th}}$ node.\n",
      "        * If there are no JAMR alignments available, then 1 point is partitioned among all tokens string-matching label $i$.\n",
      "    * Compute $\\ell(a_{W_s,L_s}[k] = a_{L_t, L_s}[i])$ by the same method.\n",
      "    * Compute $\\ell(a_{W_t,W_s}[j] = k)$ from a posterior word alignment score extracted from the source-target and target-source nbest GIZA alignment files, normalized to 1.\n",
      "\n",
      "In general, bilingual AMRICA appears to require more random restarts than monolingual AMRICA to perform well. This restart count can be modified with the flag `--num_restarts`.\n",
      "\n",
      "<img src=\"wb.eng_0003.13.png\">\n",
      "\n",
      "## Getting started\n",
      "\n",
      "Download the python source from [github](https://github.com/nsaphra/AMRICA).\n",
      "\n",
      "### Dependencies\n",
      "\n",
      "The following python packages are required to run AMRICA and can be installed with pip: `networkx`, `argparse`, `argparse_config`, `pygraphviz`.\n",
      "\n",
      "Additionally, to prepare bilingual alignment data you will need [GIZA++](https://code.google.com/p/giza-pp/) and possibly  [JAMR](https://github.com/jflanigan/jamr/).\n",
      "\n",
      "### Data Preparation\n",
      "\n",
      "#### Monolingual AMRICA\n",
      "\n",
      "To generate visualizations of Smatch alignments, we need an AMR input file with each \n",
      "`::tok` fields containing tokenized sentences, `::id` fields with a sentence ID, and `::anno` fields with an annotator ID. The annotations for a particular sentence are listed sequentially, and the first annotation is considered the gold standard for visualization purposes.\n",
      "\n",
      "If you only want to visualize the single annotation per sentence, you can use an AMR file with only a single annotator.\n",
      "\n",
      "### Bilingual AMRICA\n",
      "\n",
      "For bilingual alignments, we start with two AMR files, one containing the target annotations and one with the source annotations in the same order, with `::tok` and `::id` fields for each annotation. If we want JAMR alignments for either side, we include those in a `::alignments` field.\n",
      "\n",
      "The sentence alignments should be in the form of two GIZA++ alignment .NBEST files, one source-target and one target-source. To generate these, use the --nbestalignments flag in your GIZA++ config file set to your preferred nbest count.\n",
      "\n",
      "## Configuration\n",
      "\n",
      "Flags can be set either at the command line or in a config file. The location of a config file can be set with `-c CONF_FILE` at the command line.\n",
      "\n",
      "### Common flags\n",
      "\n",
      "In addition to `--conf_file`, there are several other flags that apply to both monolingual and bilingual text. `--outdir DIR` is the only required one, and specifies the directory to which we will write the image files.\n",
      "\n",
      "The optional shared flags are:\n",
      "* `--verbose` to print out sentences as we align them.\n",
      "* `--no-verbose` to override a verbose default setting.\n",
      "* `--json FILE.json` to write the alignment graphs to a .json file.\n",
      "* `--num_restarts N` to specify the number of random restarts Smatch should execute.\n",
      "\n",
      "### Monolingual\n",
      "\n",
      "Monolingual alignment requires one additional flag, `--infile FILE.amr`, with `FILE.amr` set to the location of the AMR file.\n",
      "\n",
      "Following is an example config file:\n",
      "\n",
      "```\n",
      "[default]\n",
      "infile: data/events_amr.txt\n",
      "outdir: data/events_png/\n",
      "json: data/events.json\n",
      "verbose\n",
      "```\n",
      "\n",
      "### Bilingual\n",
      "\n",
      "In bilingual alignment, there are more required flags.\n",
      "\n",
      "* `--src_amr FILE` for the source annotation AMR file.\n",
      "* `--tgt_amr FILE` for the target annotation AMR file.\n",
      "* `--align_tgt2src FILE.A3.NBEST` for the GIZA++ .NBEST file aligning target-to-source (with target as vcb1), generated with `--nbestalignments N`\n",
      "* `--align_src2tgt FILE.A3.NBEST` for the GIZA++ .NBEST file aligning source-to-target (with source as vcb1), generated with `--nbestalignments N`\n",
      "\n",
      "Now if `--nbestalignments N` was set to be >1, we should specify it with `--num_aligned_in_file`. If we want to count only the top $k$ of those alignments, we set `--num_align_read` as well.\n",
      "\n",
      "## Endnotes\n",
      "\n",
      "`--nbestalignments` is a tricky flag to use, because it will only generate on a final alignment run. I could only get it to work with the default GIZA++ settings, myself."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}